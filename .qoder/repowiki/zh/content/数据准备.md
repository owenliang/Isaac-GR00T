# 数据准备

<cite>
**本文档中引用的文件**   
- [data_preparation.md](file://getting_started/data_preparation.md)
- [data_config.md](file://getting_started/data_config.md)
- [modality.json](file://demo_data/cube_to_bowl_5/meta/modality.json)
- [modality.json](file://demo_data/gr1.PickNPlace/meta/modality.json)
- [types.py](file://gr00t/data/types.py)
- [embodiment_configs.py](file://gr00t/configs/data/embodiment_configs.py)
- [so100_config.py](file://examples/SO100/so100_config.py)
- [modality_config.py](file://examples/PointNav/modality_config.py)
- [info.json](file://demo_data/cube_to_bowl_5/meta/info.json)
- [lerobot_episode_loader.py](file://gr00t/data/dataset/lerobot_episode_loader.py)
- [state_action_processor.py](file://gr00t/data/state_action/state_action_processor.py)
- [convert_v3_to_v2.py](file://scripts/lerobot_conversion/convert_v3_to_v2.py)
- [modality.json](file://examples/LIBERO/modality.json)
- [modality.json](file://examples/PointNav/modality.json)
</cite>

## 目录
1. [简介](#简介)
2. [数据格式要求](#数据格式要求)
3. [数据转换指南](#数据转换指南)
4. [modality.json配置](#modalityjson配置)
5. [关键数据模型](#关键数据模型)
6. [数据处理流程](#数据处理流程)
7. [故障排除指南](#故障排除指南)
8. [性能优化技巧](#性能优化技巧)

## 简介

Isaac-GR00T数据准备文档旨在为用户提供全面的指导，帮助将原始机器人数据转换为LeRobot格式，并配置数据模态。本文档详细介绍了数据格式要求、数据转换指南和modality.json配置，解释了VLAStepData、ModalityConfig、ActionConfig等关键数据模型的结构和用途。无论是初学者还是经验丰富的开发者，都能从本文档中获得所需的信息。

**Section sources**
- [data_preparation.md](file://getting_started/data_preparation.md)
- [data_config.md](file://getting_started/data_config.md)

## 数据格式要求

Isaac-GR00T使用LeRobot数据集V2格式，并在此基础上增加了额外的结构，以支持更详细的机器人数据规范和语言注释。以下是数据格式的基本要求：

### 文件结构

数据集的文件结构应如下所示：

```
.
├─meta 
│ ├─episodes.jsonl
│ ├─modality.json # -> GR00T LeRobot 特有
│ ├─info.json
│ └─tasks.jsonl
├─videos
│ └─chunk-000
│   └─observation.images.ego_view
│     └─episode_000001.mp4
│     └─episode_000000.mp4
└─data
  └─chunk-000
    ├─episode_000001.parquet
    └─episode_000000.parquet
```

### 视频观测

视频文件应存储为MP4格式，并按照`episode_00000X.mp4`的命名格式命名，其中X表示集数编号。视频文件的命名应遵循`observation.images.<video_name>`的格式。

### 数据文件

数据文件应存储为Parquet格式，并按照`episode_00000X.parquet`的命名格式命名，其中X表示集数编号。每个Parquet文件应包含以下内容：

- **状态信息**：存储为`observation.state`，是一个一维的数组，包含所有状态模态。
- **动作**：存储为`action`，是一个一维的数组，包含所有动作模态。
- **时间戳**：存储为`timestamp`，是一个浮点数，表示观测的起始时间。
- **注释**：存储为`annotation.<annotation_source>.<annotation_type>(.<annotation_name>)`，不应有其他列使用`annotation`前缀。

### 元数据文件

- `episodes.jsonl`：包含数据集中所有集的列表。每个集包含任务列表和集的长度。
- `tasks.jsonl`：包含数据集中所有任务的列表。
- `info.json`：包含数据集信息。

**Section sources**
- [data_preparation.md](file://getting_started/data_preparation.md)
- [info.json](file://demo_data/cube_to_bowl_5/meta/info.json)

## 数据转换指南

### 转换LeRobot V3.0到V2.0

如果您的数据集是LeRobot V3.0格式，可以使用`convert_v3_to_v2.py`脚本将其转换为LeRobot V2.0格式。该脚本会将V3.0的数据集转换为V2.1的格式，并保留所有必要的元数据。

```python
from scripts.lerobot_conversion.convert_v3_to_v2 import convert_dataset

convert_dataset(repo_id="your_dataset_repo_id", root="path/to/dataset", force_conversion=True)
```

### 转换其他格式

如果您的数据集是其他格式，需要先将其转换为LeRobot V2.0格式。确保数据集满足以下要求：

- 文件结构符合上述要求。
- 视频文件存储为MP4格式。
- 数据文件存储为Parquet格式。
- 元数据文件包含必要的信息。

**Section sources**
- [data_preparation.md](file://getting_started/data_preparation.md)
- [convert_v3_to_v2.py](file://scripts/lerobot_conversion/convert_v3_to_v2.py)

## modality.json配置

`modality.json`文件是GR00T LeRobot特有的元数据文件，用于提供状态和动作模态的详细信息。该文件的主要作用包括：

- **分离数据存储和解释**：状态和动作存储为连接的float32数组，`modality.json`文件提供必要的元数据来解释这些数组为不同的细粒度字段。
- **细粒度分割**：将状态和动作数组分割为更多语义上有意义的字段。
- **清晰映射**：明确映射数据维度。
- **复杂数据转换**：支持字段特定的归一化和旋转转换。

### Schema

```json
{
    "state": {
        "<state_key>": {
            "start": <int>,         // 状态数组中的起始索引
            "end": <int>            // 状态数组中的结束索引
        }
    },
    "action": {
        "<action_key>": {
            "start": <int>,         // 动作数组中的起始索引
            "end": <int>            // 动作数组中的结束索引
        }
    },
    "video": {
        "<new_key>": {
            "original_key": "<original_video_key>"
        }
    },
    "annotation": {
        "<annotation_key>": {}  // 为空字典以保持与其他模态的一致性
    }
}
```

### 示例

```json
{
    "state": {
        "single_arm": {
            "start": 0,
            "end": 5
        },
        "gripper": {
            "start": 5,
            "end": 6
        }
    },
    "action": {
        "single_arm": {
            "start": 0,
            "end": 5
        },
        "gripper": {
            "start": 5,
            "end": 6
        }
    },
    "video": {
        "front": {
            "original_key": "observation.images.front"
        },
        "wrist": {
            "original_key": "observation.images.wrist"
        }
    },
    "annotation": {
        "human.task_description": {
            "original_key": "task_index"
        }
    }
}
```

**Section sources**
- [data_preparation.md](file://getting_started/data_preparation.md)
- [modality.json](file://demo_data/cube_to_bowl_5/meta/modality.json)
- [modality.json](file://demo_data/gr1.PickNPlace/meta/modality.json)

## 关键数据模型

### VLAStepData

`VLAStepData`是VLA（视觉-语言-动作）数据的核心数据结构，表示单个步骤的数据。它包含原始观测和动作数据，这些数据将由`SequenceVLAProcessor`处理。

```python
@dataclass
class VLAStepData:
    images: dict[str, list[np.ndarray]]  # view_name -> list[np.ndarray] (用于时间堆叠)
    states: dict[str, np.ndarray]       # state_name -> np.ndarray (dim,) 用于单步或 (horizon, dim) 用于轨迹
    actions: dict[str, np.ndarray]      # action_name -> np.ndarray (horizon, dim) 用于动作块
    text: str | None = None             # 可选的任务描述或指令
    embodiment: EmbodimentTag = EmbodimentTag.NEW_EMBODIMENT  # 可选的实体标签，用于跨实体训练
    is_demonstration: bool = False      # 步骤是否为演示。如果为True，则不应为此步骤计算损失
    metadata: dict[str, Any] = field(default_factory=dict)  # 可扩展的元数据
```

### ModalityConfig

`ModalityConfig`类定义了如何采样和加载特定模态的数据。它包含两个必需字段和几个可选字段。

#### 必需字段

- **`delta_indices` (list[int])**：定义相对于当前时间步的采样时间偏移。例如，`[-2, -1, 0]`表示使用过去3个时间步的数据。
- **`modality_keys` (list[str])**：指定从数据集中加载的键。这些键必须与`modality.json`文件中的键匹配。

#### 可选字段

- **`sin_cos_embedding_keys` (list[str] | None)**：指定哪些状态键应使用正弦/余弦编码。适用于以弧度表示的维度（如关节角度）。
- **`mean_std_embedding_keys` (list[str] | None)**：指定哪些键应使用均值/标准差归一化而不是最小/最大归一化。
- **`action_configs` (list[ActionConfig] | None)**：用于`"action"`模态，定义每个动作模态的解释和转换方式。

### ActionConfig

`ActionConfig`类定义了如何解释和转换每个动作模态。它包含三个必需字段和一个可选字段。

#### 必需字段

- **`rep` (ActionRepresentation)**：定义动作的解释方式。`RELATIVE`表示动作是相对于当前状态的增量，`ABSOLUTE`表示动作是目标位置。
- **`type` (ActionType)**：指定控制空间。`EEF`表示末端执行器/笛卡尔空间控制，`NON_EEF`表示关节空间控制和其他非末端执行器控制空间。
- **`format` (ActionFormat)**：定义动作表示格式。`DEFAULT`表示标准格式（如关节角度、夹爪位置），`XYZ_ROT6D`表示3D位置+6D旋转表示，`XYZ_ROTVEC`表示3D位置+旋转向量。

#### 可选字段

- **`state_key` (str | None)**：指定用于计算相对动作的参考状态键。如果未提供，系统将使用动作键作为参考状态键。

**Section sources**
- [types.py](file://gr00t/data/types.py)
- [data_config.md](file://getting_started/data_config.md)

## 数据处理流程

### 数据加载

`LeRobotEpisodeLoader`类负责加载和预处理LeRobot数据集中的单个集。它管理元数据解析、视频解码和多模态数据提取。

```python
class LeRobotEpisodeLoader:
    def __init__(
        self,
        dataset_path: str | Path,
        modality_configs: dict[str, ModalityConfig],
        video_backend: str = "torchcodec",
        video_backend_kwargs: dict[str, Any] | None = None,
    ) -> None:
        self.dataset_path = Path(dataset_path)
        self.video_backend = video_backend
        self.video_backend_kwargs = video_backend_kwargs
        self._load_metadata()
        self.modality_configs = self._parse_and_validate_modality_configs(modality_configs)
        self.episode_lengths = self.get_episode_lengths()
```

### 数据处理

`StateActionProcessor`类负责处理机器人状态和动作数据，包括状态归一化、动作归一化、绝对到相对动作表示的转换等。

```python
class StateActionProcessor:
    def __init__(
        self,
        modality_configs: dict[str, dict[str, ModalityConfig]],
        statistics: dict[str, dict[str, dict[str, dict[str, list[float]]]]] | None = None,
        use_percentiles: bool = False,
        clip_outliers: bool = True,
        apply_sincos_state_encoding: bool = False,
        use_relative_action: bool = False,
    ):
        self.modality_configs = parse_modality_configs(modality_configs)
        self.statistics = {}
        self.use_percentiles = use_percentiles
        self.clip_outliers = clip_outliers
        self.apply_sincos_state_encoding = apply_sincos_state_encoding
        self.use_relative_action = use_relative_action
        self.norm_params = {}
        if statistics is not None:
            self.set_statistics(statistics)
        self.train()
```

**Section sources**
- [lerobot_episode_loader.py](file://gr00t/data/dataset/lerobot_episode_loader.py)
- [state_action_processor.py](file://gr00t/data/state_action/state_action_processor.py)

## 故障排除指南

### 常见问题

1. **数据集路径不存在**：确保数据集路径正确，并且包含所有必要的文件和目录。
2. **视频文件无法解码**：检查视频文件是否为MP4格式，并且没有损坏。
3. **元数据文件缺失**：确保`meta`目录中包含所有必要的元数据文件。
4. **数据维度不匹配**：检查`modality.json`文件中的`start`和`end`索引是否正确。

### 解决方案

- **检查文件结构**：确保数据集的文件结构符合要求。
- **验证文件格式**：确保视频文件为MP4格式，数据文件为Parquet格式。
- **核对元数据**：确保元数据文件中的信息与数据文件中的信息一致。
- **调试代码**：使用调试工具检查代码中的错误，并逐步排查问题。

**Section sources**
- [data_preparation.md](file://getting_started/data_preparation.md)
- [lerobot_episode_loader.py](file://gr00t/data/dataset/lerobot_episode_loader.py)

## 性能优化技巧

### 数据预处理

- **批量处理**：尽可能批量处理数据，以减少I/O操作。
- **缓存**：缓存常用的数据，避免重复计算。
- **并行处理**：使用多线程或多进程并行处理数据。

### 模型训练

- **数据增强**：使用数据增强技术增加数据多样性。
- **学习率调度**：使用学习率调度器调整学习率，提高训练效率。
- **正则化**：使用正则化技术防止过拟合。

**Section sources**
- [state_action_processor.py](file://gr00t/data/state_action/state_action_processor.py)
- [data_config.md](file://getting_started/data_config.md)