#!/usr/bin/env python
import json
import logging
import os
from pathlib import Path
import warnings

from omegaconf import OmegaConf
import torch
import torch.distributed as dist
from transformers import TrainingArguments, set_seed
import wandb

from gr00t.configs.base_config import Config

# Use custom trainer that profiles data loading & forward times
from gr00t.experiment.trainer import Gr00tTrainer, ProfCallback
from gr00t.experiment.utils import BestMetricCheckpointCallback, CheckpointFormatCallback
from gr00t.model import MODEL_REGISTRY
from gr00t.utils.initial_actions import INITIAL_ACTIONS_FILENAME, save_initial_actions


def setup_logging(debug: bool = False):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿï¼Œå‡å°‘ transformers å’Œ datasets åº“çš„å†—ä½™è¾“å‡ºã€‚"""
    logging.basicConfig(
        level=logging.DEBUG if debug else logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        datefmt="%m/%d/%Y %H:%M:%S",
    )
    # Reduce verbosity of some libraries
    logging.getLogger("transformers").setLevel(logging.WARNING)
    logging.getLogger("datasets").setLevel(logging.WARNING)


def warn_configs(config: Config):
    """æ ¡éªŒé…ç½®å¹¶å‘å‡ºå¼ƒç”¨è­¦å‘Šï¼Œé¿å…å¸¸è§é…ç½®é”™è¯¯ã€‚"""
    # updates to batch size
    assert config.training.global_batch_size % config.training.num_gpus == 0, (
        "global_batch_size must be divisible by num_gpus"
    )

    if config.data.video_backend != "torchcodec":
        warnings.warn(
            "video_backend is not torchcodec. Only torchcodec will be supported in the future."
        )

    if config.training.batch_size is not None:
        warnings.warn(
            "batch_size will be deprecated in the future, please use global_batch_size instead. For now, this will override global_batch_size."
        )

    if config.training.warmup_steps > 0:
        warnings.warn(
            "warmup_steps will be deprecated in the future, please use warmup_ratio instead. For now, this will override warmup_ratio."
        )

    if (
        hasattr(config.model, "backbone_trainable_params_fp32")
        and not config.model.backbone_trainable_params_fp32
    ):
        warnings.warn(
            "backbone_trainable_params_fp32 is not True. This will be deprecated in the future."
        )

    if (
        hasattr(config.model, "use_albumentations_transforms")
        and not config.model.use_albumentations_transforms
    ):
        warnings.warn(
            "use_albumentations_transforms is not True. This will be deprecated in the future."
        )

    if (
        hasattr(config.model, "image_crop_size")
        and hasattr(config.model, "image_target_size")
        and (config.model.image_crop_size is not None or config.model.image_target_size is not None)
    ):
        assert (
            config.model.image_crop_size is not None and config.model.image_target_size is not None
        ), "image_crop_size and image_target_size must be set together"
        warnings.warn(
            "image_crop_size and image_target_size will be deprecated in the future. Please use shortest_image_edge and crop_fraction instead."
        )
        if hasattr(config.model, "shortest_image_edge") and hasattr(config.model, "crop_fraction"):
            assert (
                config.model.shortest_image_edge is None and config.model.crop_fraction is None
            ), (
                "Do not set shortest_image_edge and crop_fraction together with image_crop_size and image_target_size"
            )

    if (
        hasattr(config.model, "shortest_image_edge")
        and hasattr(config.model, "crop_fraction")
        and (config.model.shortest_image_edge is not None or config.model.crop_fraction is not None)
    ):
        assert config.model.use_albumentations_transforms, (
            "use_albumentations_transforms must be True when shortest_image_edge and crop_fraction are set"
        )


def run(config: Config):
    """è®­ç»ƒä¸»æµç¨‹ï¼šåˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ â†’ æ„å»ºæ¨¡å‹/æ•°æ® â†’ å¯åŠ¨ Trainerã€‚"""
    warn_configs(config)

    # åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒï¼ˆå¦‚æœéœ€è¦ï¼‰
    # æ”¯æŒ torchrun å’Œæ™®é€šå•æœºæ¨¡å¼
    if dist.is_initialized():
        global_rank = dist.get_rank()
    elif "WORLD_SIZE" in os.environ and int(os.environ["WORLD_SIZE"]) > 1:
        # å¤šè¿›ç¨‹æ¨¡å¼ï¼šä½¿ç”¨ NCCL è¿›è¡Œåˆ†å¸ƒå¼é€šä¿¡
        dist.init_process_group(backend="nccl")
        # only meaningful for torchrun, for ray it is always 0
        local_rank = int(os.environ["LOCAL_RANK"])
        torch.cuda.set_device(local_rank)
        global_rank = dist.get_rank()
    else:
        local_rank = 0
        global_rank = 0

    # åŸºç¡€è®¾ç½®ï¼šæ—¥å¿—ã€éšæœºç§å­ã€é…ç½®æ ¡éªŒ
    setup_logging()
    set_seed(config.data.seed)

    # æ ¡éªŒé…ç½®ï¼ˆembodiment tagã€mix_ratioã€action config ç­‰ï¼‰
    config.validate()

    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆä¿å­˜ checkpointsã€æ—¥å¿—ç­‰ï¼‰
    if config.training.experiment_name is None:
        output_dir = Path(config.training.output_dir)
        experiment_name = output_dir.name
    else:
        output_dir = Path(config.training.output_dir) / config.training.experiment_name
        experiment_name = config.training.experiment_name

    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜é…ç½®æ–‡ä»¶ï¼ˆç”¨äºå¤ç°å’Œæ¨ç†ï¼‰
    save_cfg_dir = output_dir / "experiment_cfg"
    processor_dir = output_dir / "processor"
    config.save(save_cfg_dir / "config.yaml")
    omegaconf_config = OmegaConf.create(config.__dict__)
    omegaconf_config["max_steps"] = config.training.max_steps
    omegaconf_config["save_steps"] = config.training.save_steps
    OmegaConf.save(omegaconf_config, save_cfg_dir / "conf.yaml", resolve=True)
    wandb_config_file = output_dir / "wandb_config.json"
    with open(wandb_config_file, "w") as f:
        json.dump(
            {
                "project": config.training.wandb_project,
                "run_id": experiment_name,
            },
            f,
        )

    logging.info(f"Saved config to {save_cfg_dir}")

    # åˆå§‹åŒ– WandBï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
    if config.training.use_wandb and global_rank == 0:
        # Add git commit hash and version info to config
        config_dict = {
            **config.__dict__,
            "git_commit_hash": os.environ.get("GROOT_COMMIT_HASH", "unknown"),
        }

        wandb.init(
            project=config.training.wandb_project,
            name=experiment_name,
            config=config_dict,
            tags=[config.data.mode],
        )

    # æ ¸å¿ƒï¼šé€šè¿‡ MODEL_REGISTRY è·å–æ¨¡å‹ Pipeline
    # Pipeline è´Ÿè´£æ„å»ºæ¨¡å‹ã€æ•°æ®é›†ã€Processorã€Collator
    # ã€ä¸­æ–‡ã€‘æ³¨å†Œè¡¨æ¨¡å¼ï¼š
    # 1. type(config.model) è·å–é…ç½®ç±»å‹ï¼ˆå¦‚ Gr00tN1d6Configï¼‰
    # 2. MODEL_REGISTRY.get(...) æŸ¥æ‰¾å¯¹åº”çš„ Pipeline ç±»ï¼ˆå¦‚ Gr00tN1d6Pipelineï¼‰
    # 3. (config, save_cfg_dir) å®ä¾‹åŒ– Pipeline å¯¹è±¡
    pipeline = MODEL_REGISTRY.get(type(config.model))(config, save_cfg_dir) # ç”±gr00t/model/__init__.pyåˆå§‹åŒ–æ³¨å†Œäº†gr00tæ¨¡å‹
    pipeline.setup()  # åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶ï¼Œä¸»è¦ç”¨é€”æ˜¯åˆ›å»ºæ¨¡å‹ã€åˆ›å»ºè®­ç»ƒæ•°æ®é›†ã€dataloaderæ•°æ®å¤„ç†æ–¹æ³•
    model = pipeline.return_model() # è·å–æ¨¡å‹
    train_dataset, eval_dataset = pipeline.return_dataset() # è·å–è®­ç»ƒ/è¯„ä¼°æ•°æ®é›†
    data_collator = pipeline.return_collator() # è·å–æ•°æ®_collator
    processor = pipeline.return_processor()
    processor.save_pretrained(processor_dir)

    # DeepSpeed é…ç½®ï¼ˆå¤š GPU ä¸”ä¸ä½¿ç”¨ DDP æ—¶ï¼‰
    if config.training.num_gpus > 1 and not config.training.use_ddp:
        deepspeed_config = config.get_deepspeed_config()
    else:
        deepspeed_config = None

    # è®¡ç®—æ¯ä¸ªè®¾å¤‡çš„ batch size
    # for now we will let batch_size override global_batch_size, in future we will deprecate batch_size
    if config.training.batch_size is None:
        per_device_train_batch_size = config.training.global_batch_size // config.training.num_gpus
    else:
        per_device_train_batch_size = config.training.batch_size

    # åˆ›å»º HuggingFace TrainingArgumentsï¼ˆå°è£…æ‰€æœ‰è®­ç»ƒè¶…å‚æ•°ï¼‰
    training_args = TrainingArguments(
        output_dir=str(output_dir),
        max_steps=config.training.max_steps,
        per_device_train_batch_size=per_device_train_batch_size,
        per_device_eval_batch_size=config.training.eval_batch_size,
        gradient_accumulation_steps=config.training.gradient_accumulation_steps,
        learning_rate=config.training.learning_rate,
        lr_scheduler_type=config.training.lr_scheduler_type,
        weight_decay=config.training.weight_decay,
        warmup_ratio=config.training.warmup_ratio,
        max_grad_norm=config.training.max_grad_norm,
        logging_steps=config.training.logging_steps,
        save_steps=config.training.save_steps,
        save_total_limit=config.training.save_total_limit,
        fp16=config.training.fp16,
        bf16=config.training.bf16,
        tf32=config.training.tf32,
        gradient_checkpointing=config.training.gradient_checkpointing,
        optim=config.training.optim,
        dataloader_num_workers=config.training.dataloader_num_workers,
        report_to="wandb" if config.training.use_wandb else "none",
        seed=config.data.seed,
        deepspeed=deepspeed_config,
        ddp_find_unused_parameters=False,
        ddp_bucket_cap_mb=config.training.ddp_bucket_cap_mb,
        eval_strategy=config.training.eval_strategy,
        eval_steps=config.training.eval_steps,
        batch_eval_metrics=True,
        remove_unused_columns=config.training.remove_unused_columns,
        ignore_data_skip=True,
    )

    # åˆ›å»ºè‡ªå®šä¹‰ Trainerï¼ˆæ”¯æŒ profilingã€è‡ªå®šä¹‰ dataloaderï¼‰
    # ã€ä¸­æ–‡ã€‘multiprocessing_context æŒ‡å®šå¤šè¿›ç¨‹å¯åŠ¨æ–¹å¼ï¼š
    # - "fork": å¤åˆ¶çˆ¶è¿›ç¨‹å†…å­˜ï¼ˆLinuxé»˜è®¤ï¼Œå¿«é€Ÿä½†å¯èƒ½æœ‰CUDAé—®é¢˜ï¼‰
    # - "spawn": å¯åŠ¨å…¨æ–°è¿›ç¨‹ï¼ˆWindowsé»˜è®¤ï¼Œå®‰å…¨ä½†æ…¢ï¼‰
    # - "forkserver": ä½¿ç”¨æœåŠ¡å™¨è¿›ç¨‹forkï¼ˆå¹³è¡¡æ€§èƒ½å’Œå®‰å…¨æ€§ï¼‰
    trainer = Gr00tTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        data_collator=data_collator,
        multiprocessing_context=config.data.multiprocessing_context,
    )

    # æ·»åŠ  checkpoint æ ¼å¼åŒ–å›è°ƒï¼ˆä¿å­˜æ—¶è‡ªåŠ¨æ•´ç†é…ç½®æ–‡ä»¶ï¼‰
    trainer.add_callback(
        CheckpointFormatCallback(
            run_name=experiment_name,
            exp_cfg_dir=save_cfg_dir,
            processor_dir=processor_dir,
        )
    )

    # å¯é€‰ï¼šä¿å­˜æœ€ä½³è¯„ä¼°æŒ‡æ ‡çš„ checkpoint
    if config.training.save_best_eval_metric_name != "":
        trainer.add_callback(
            BestMetricCheckpointCallback(
                metric_name=config.training.save_best_eval_metric_name,
                greater_is_better=config.training.save_best_eval_metric_greater_is_better,
                exp_cfg_dir=save_cfg_dir,
            )
        )

    # å¦‚æœæ•°æ®é›†æ”¯æŒï¼Œä¿å­˜åˆå§‹åŠ¨ä½œï¼ˆç”¨äºæŸäº›ä»»åŠ¡çš„åˆå§‹åŒ–ï¼‰
    if hasattr(train_dataset, "get_initial_actions"):
        initial_actions = train_dataset.get_initial_actions()
        if initial_actions:
            initial_actions_path = save_cfg_dir / INITIAL_ACTIONS_FILENAME
            save_initial_actions(initial_actions, initial_actions_path)
            logging.info(f"Saved {len(initial_actions)} initial actions to {initial_actions_path}")

    # å¼€å§‹è®­ç»ƒ
    logging.info("ğŸš€ Starting training...")
    if config.training.enable_profiling:
        # æ€§èƒ½åˆ†ææ¨¡å¼ï¼šä½¿ç”¨ torch.profiler è®°å½• CPU/CUDA æ‰§è¡Œè½¨è¿¹
        from functools import partial

        logging.info(f"{global_rank} Starting training with profiling...")

        def on_trace_ready_handler(trainer, profile_dir, prof):
            output_path = (
                profile_dir / f"trace_rank_{global_rank}_iter_{trainer.state.global_step}.json"
            )
            prof.export_chrome_trace(str(output_path))
            logging.info(f"Trace saved to {output_path}")

        profile_dir = output_dir / "profiling"
        profile_dir.mkdir(parents=True, exist_ok=True)

        # ã€ä¸­æ–‡ã€‘torch.profiler.profile æ˜¯ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œè‡ªåŠ¨ç®¡ç† profiler çš„ç”Ÿå‘½å‘¨æœŸ
        # ã€ä¸­æ–‡ã€‘schedule å‚æ•°å®šä¹‰äº†æ€§èƒ½åˆ†æçš„é˜¶æ®µï¼š
        # - skip_first=10: è·³è¿‡å‰10ä¸ªstepï¼ˆé¿å…å¯åŠ¨å¼€é”€å¹²æ‰°ï¼‰
        # - wait=1: ç­‰å¾…1ä¸ªstep
        # - warmup=1: é¢„çƒ­1ä¸ªstep
        # - active=3: æ´»è·ƒè®°å½•3ä¸ªstep
        # - repeat=1: é‡å¤1æ¬¡å‘¨æœŸ
        # ã€ä¸­æ–‡ã€‘ProfCallback.on_step_end() ä¼šè°ƒç”¨ prof.step()ï¼Œé€šçŸ¥ profiler è¿›å…¥ä¸‹ä¸€ä¸ªé˜¶æ®µ
        # ã€ä¸­æ–‡ã€‘profiler æ ¹æ® schedule è‡ªåŠ¨åˆ‡æ¢çŠ¶æ€ï¼ˆwait â†’ warmup â†’ active â†’ wait...ï¼‰
        with torch.profiler.profile(
            activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],
            schedule=torch.profiler.schedule(skip_first=10, wait=1, warmup=1, active=3, repeat=1),
            # profile_memory=True,
            with_stack=True,
            # record_shapes=True,
            on_trace_ready=partial(on_trace_ready_handler, trainer, profile_dir),
        ) as prof:
            trainer.add_callback(ProfCallback(prof=prof))
            trainer.train(resume_from_checkpoint=True)
    else:
        # æ­£å¸¸è®­ç»ƒæ¨¡å¼
        # ã€ä¸­æ–‡ã€‘resume_from_checkpoint=True çš„å¤„ç†é€»è¾‘ï¼š
        # 1. Gr00tTrainer.train() æ¥æ”¶åˆ° True
        # 2. è°ƒç”¨ get_last_checkpoint(self.args.output_dir) æŸ¥æ‰¾æœ€æ–°çš„ checkpoint
        # 3. output_dir æ¥è‡ª TrainingArguments(output_dir=str(output_dir))
        # 4. output_dir æ¥è‡ª experiment.py çš„ config.training.output_dir
        # ã€ä¸­æ–‡ã€‘æŸ¥æ‰¾é€»è¾‘ï¼šåœ¨ output_dir ä¸­æ‰¾åˆ°æ‰€æœ‰ä»¥ 'checkpoint-' å¼€å¤´çš„ç›®å½•ï¼Œè¿”å›æœ€æ–°çš„ä¸€ä¸ª
        # ã€ä¸­æ–‡ã€‘ç¤ºä¾‹ï¼šoutput_dir/checkpoint-1000, checkpoint-2000 â†’ è¿”å› checkpoint-2000
        trainer.train(resume_from_checkpoint=True)

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    trainer.save_model()
    logging.info(f"Model saved to {output_dir}")

    # å¯é€‰ï¼šæ–­è¨€æœ€ç»ˆ loss å°äºæŸä¸ªé˜ˆå€¼ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    if config.training.assert_loss_less_than is not None:
        final_loss = trainer.loss
        if final_loss.item() > config.training.assert_loss_less_than:
            raise AssertionError(
                f"Loss too high: {final_loss.item()} vs {config.training.assert_loss_less_than})"
            )

    # æ¸…ç†èµ„æº
    if hasattr(train_dataset, "close"):
        train_dataset.close()
    if eval_dataset is not None and hasattr(eval_dataset, "close"):
        eval_dataset.close()
    logging.info("Training completed!")
